\chapter{Back-End}
\section{Konzept}
\section{Verwendete Open-Source Bibliotheken}
\subsection{OpenCV}
Bei OpenCV (Open Source Computer Vision Library) handelt es sich um eine Bibliothek zur Verarbeitung und Bearbeitung von Bildern und Video Formaten.  OpenCV wurde in C/C++ entwickelt und unterliegt derzeit einer Lizenz die eine kostenlose Nutzung für akademische als auch kommerzielle ermöglicht. Die Bibliothek unterstützt nicht nur herkömmliche Betriebssysteme wie Windows, Linux und Max OS, sondern auch Mobile Betriebssysteme wie iOS und Android. OpenCV wurde so entwickelt, dass es effizient in Echtzeitsystemen genutzt werden kann. In unserem Projekt werden wir für die Bearbeitung des Video-Streams mehrere Funktionalitäten der Bibliothek aufgreifen und verwenden.
\subsection{Numpy}
Bei NumPy handelt es sich um eine Python exklusive Bibliothek. Diese wurde entwickelt, um mathematische Funktionen anzuwenden. Der Schwerpunkt hierbei liegt ins besonders auf Matrizen. Auch Numpy unterliegt der gleichen Lizenz wie OpenCV und erlaubt daher eine kostenlose Nutzung. In unserem System benötigen wir Numpy um ein paar Operationen auf unsere Bilder anzuwenden oder auch um exemplarisch Bilder zu erstellen.
\section{Bildverarbeitungsprozess}
Um eine Bewegung aus mehreren Bildern erkennen zu können, reicht es normalerweise aus, die jeweiligen Pixelpositionen voneinander zu subtrahieren. Hat man an diesem Punkt noch weiße bzw. farbige Pixel, kann man davon ausgehen, dass es einen Unterschied gibt und daher auch eine Bewegung vorhanden ist. Da wir nun die Bewegungserkennungen einer Kamera umsetzen sollen, kann man nicht so simple vorgehen. Es gibt mehrere kleinere Aspekte die Beachtet werden können und es gibt auch keine einfache Lösung für einige Probleme. Im Laufe dieses Kapitels werden einige Probleme beleuchtet als auch Lösungen für diese aufgeführt, sofern diese umsetzbar sind. 
In dem Ablaufdiagramm kann man die Vorgehensweise unserer Bildverarbeitung sehen. Der erste Schritt beinhaltet die Konvertierung eines Farbwertbilds in ein Grauwertbild. Diese kann mit Hilfe von OpenCV leicht umgesetzt werden. Somit muss man sich keine Gedanken um den Datentyp des Bildes machen. Der Sinn hinter dieser Konvertierung bezieht sich stark auf die Performanz der kommenden Operationen, die zur Bewegungserkennung notwendig sind. Würden wir alle Operationen mit einem Farbwertbild durchführen, hätten wir mindestens eine dreimal längere Laufzeit für die Bildverarbeitung.
Als nächsten Schritt entfernen wir das Rauschen aus dem Grauwertbild. Bei Rauschen in einem Bild handelt es sich um Pixelfehler die Werte enthalten, die dem eigentlichen Farbschema widersprechen. Diese entstehen meist direkt durch das Aufnahmegerät. Mithilfe des in OpenCV gebotenen Gaussain-Filters können diese bereinigt werden. Hierbei werden die umliegenden Pixel angeschaut und anhand denen entschieden, welchen Wert er erhalten wird. Sprich liegt der Pixel in einer dunklen grauen Fläche wird auch der Pixelwert den entsprechenden Grauwert erhalten.
Da wir nun das neue Bild vorbereitet haben, benötigen wir noch das vorherige Bild für den Vergleich. In unserem Fall Berechnen wir ein Durschnitts-Bild aus den letzten 15 Bildern. Durch dieses Vorgehen sollen kleinere Bewegungen von der Bewegungserkennung ignoriert werden. Für das Speichern der Bilder nutzen wir eine zyklische Liste, die das älteste Objekt beim überschreiten der maximalen Anzahl entfernt. Für die Berechnung des Durschnitts-Bildes bietet OpenCV leider keine Funktion. Daher greifen wir auf die Bibliothek NumPy zurück. Diese ermöglicht uns sowohl die Addition als auch das Berechnen des Medians. Gibt es keinen Fehler bei der Berechnung wird uns das Durchschnittsbild zurückgegeben, ansonsten erhalten wir das zuletzt hinzugefügte Bild zurück.
Haben wir nun das Durschnitts-Bild und das letzte Bild, können wir diese voneinander subtrahieren. Somit haben wir die Unterschiede aus den letzten Bildern. Die Subtraktion können wir direkt mit OpenCV ausführen.
Als Ergebnis der Subtraktion erhalten wir ein Bild mit unterschiedlichen Grauwerten. Wenn Grauwerte voneinander abgezogen werden, kann es sein, dass ähnliche Grauwerte trotzdem einen Grauwert größer als „0“ zurückgeben. Für uns spielen aber größere Änderungen eine Rolle. Um die niedrigen Grauwerte zu filtern, kann ein Threshold angewandt werden. Durch die Threshold-Funktion von OpenCV ist es uns möglich die Grauwerte mit einer Grenze in Schwarz und Weiß aufzuteilen.  Sprich alle Grauwerte  bis Beispielsweise dem Wert von 30 werden zu schwarz und alle höheren Grauwerte werden weiß.
Da wir kleine Bewegungen nicht als Bewegung zählen lassen wollen, müssen wir kleine Bereiche vorher entfernen. Durch die sogenannte Opening-Operation können kleine Bereiche gefiltert werden. Hierbei werden zuerst alle Bereiche erodiert und die übriggebliebenen Bereiche werden dilatiert. Dadurch bleiben die größeren Bereiche bestehen und kleine Bereiche werden entfernt. OpenCV bietet für die Erosion und Dilatation separate Funktionen an, die sich leicht verwenden lassen.
Als letzten Schritt Extrahieren wir, falls vorhanden, übrig gebliebene Konturen. Gibt es eine Kontur, gab es auch eine Bewegung, und die Pixelkoordinaten der Konturen werden in das Farbwertbild übernommen, um die Bewegung kenntlich zu machen und gegeben falls werden Empfänger per Email benachrichtigt.
\section{Zusätzliche Features}
\subsection{Video, Log und Thumbnail}
Es gibt mehrere Aspekte die wichtig für die Bildverarbeitung sind. Da wir über das Backend die Bilder für das Frontend zu Verfügung stellen und auch das Video erstellen, muss einiges in dieser Hinsicht beachtet werden. Zu Beginn haben wir sofort Video, Log und Thumbnail bei der ersten Bewegungserkennung zu Verfügung gestellt. Dies hatte zur Folge, dass beim Aktivieren des Videos die Aufnahme nicht fertiggestellt wird. Und kein Video angezeigt wird. Um dies zu umgehen, werden Video, Log und Thumbnail nur beim Abschluss der Bewegungssequenz weitergeleitet und das Thumbnail kann ein Bild mitten in der Bewegung darstellen.
\subsection{FPS-Berechnung}
OpenCV bietet eine Schnittstelle zum Erstellen von Videos. Hierbei muss vorab eine feste FPS (Frames Per Second) angegeben werden. Während den Tests ist uns aufgefallen, dass das Backend je nach System unterschiedlich schnell arbeitet. Zusätzlich dazu ist die Geschwindigkeit des Videos durch eine falsche Bearbeitungsrate verzerrt. Um dies zu vermeiden, berechnen wir die durchschnittliche FPS zur Laufzeit. Die ersten hundert benötigten Zeiten werden in einer Liste abgespeichert und am Schluss dividiert. Anhand dieses Wertes erhalten wir einen guten Wert, der auch das Video in einer angemessenen Geschwindigkeit darstellt.
\subsection{Maximale Cliplänge}
Um eine maximale Cliplänge gewährleisten zu können muss die Bearbeitungsrate aufgegriffen werden. Wurden genug Bilder gesammelt (FPS x maximale Cliplänge in Sekunden) wird das Video abgebrochen und eine neue Aufnahme wird gegebenenfalls gestartet.
\subsection{Wait for Motion-end}
Wurde gerade eine Bewegung erkannt und die Bewegungen haben aufgehört, wartet die Bearbeitung noch einen Moment ab, ob nicht doch noch eine Bewegung auftaucht. Dadurch wird die Aufnahme nicht direkt beendet, wenn keine Bewegung mehr erkannt wird und ein eventuell kurzer Aussetzer der Bewegung wird ignoriert.
